{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DL_Lesson_1a.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pTRagYcvHjDj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":79},"outputId":"7481fd91-d3b5-400a-b80f-e5a18906d884","executionInfo":{"status":"ok","timestamp":1584728772634,"user_tz":300,"elapsed":5229,"user":{"displayName":"Dileep Reddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUeOYhgkcy7IK_3VWG8xk-C8gxZpv-FF_AuC_N4w=s64","userId":"05071958161747460000"}}},"source":["import pandas\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ApzFGDkOHnt7","colab_type":"code","colab":{}},"source":["dataset = pd.read_csv(\"drive/My Drive/python/DL_icp1/diabetes.csv\", header=None).values"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTu7-0t7OQ5I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"outputId":"52215ccb-e4ba-4c62-a711-5f363a50f3d7","executionInfo":{"status":"ok","timestamp":1584729261229,"user_tz":300,"elapsed":25497,"user":{"displayName":"Dileep Reddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUeOYhgkcy7IK_3VWG8xk-C8gxZpv-FF_AuC_N4w=s64","userId":"05071958161747460000"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yt64olkkHwft","colab_type":"code","colab":{}},"source":["X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],test_size=0.25, random_state=87)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d31zma3SH1KX","colab_type":"code","colab":{}},"source":["np.random.seed(42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMfomxTmH3ww","colab_type":"code","outputId":"53d9daa9-80aa-483f-8843-f846dd24c3fa","executionInfo":{"status":"ok","timestamp":1584729284110,"user_tz":300,"elapsed":4271,"user":{"displayName":"Dileep Reddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUeOYhgkcy7IK_3VWG8xk-C8gxZpv-FF_AuC_N4w=s64","userId":"05071958161747460000"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(21, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,initial_epoch=0)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","576/576 [==============================] - 1s 1ms/step - loss: 4.1907 - acc: 0.5000\n","Epoch 2/100\n","576/576 [==============================] - 0s 37us/step - loss: 3.0703 - acc: 0.5677\n","Epoch 3/100\n","576/576 [==============================] - 0s 39us/step - loss: 2.4938 - acc: 0.5851\n","Epoch 4/100\n","576/576 [==============================] - 0s 41us/step - loss: 2.2859 - acc: 0.5903\n","Epoch 5/100\n","576/576 [==============================] - 0s 37us/step - loss: 2.0512 - acc: 0.6146\n","Epoch 6/100\n","576/576 [==============================] - 0s 41us/step - loss: 1.8004 - acc: 0.6163\n","Epoch 7/100\n","576/576 [==============================] - 0s 47us/step - loss: 1.6019 - acc: 0.6267\n","Epoch 8/100\n","576/576 [==============================] - 0s 40us/step - loss: 1.4857 - acc: 0.6059\n","Epoch 9/100\n","576/576 [==============================] - 0s 56us/step - loss: 1.3588 - acc: 0.6111\n","Epoch 10/100\n","576/576 [==============================] - 0s 41us/step - loss: 1.1911 - acc: 0.6510\n","Epoch 11/100\n","576/576 [==============================] - 0s 44us/step - loss: 1.0434 - acc: 0.6667\n","Epoch 12/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.9841 - acc: 0.6476\n","Epoch 13/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.9340 - acc: 0.6562\n","Epoch 14/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.7864 - acc: 0.6632\n","Epoch 15/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.7428 - acc: 0.6580\n","Epoch 16/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.7118 - acc: 0.6771\n","Epoch 17/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.6853 - acc: 0.6771\n","Epoch 18/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.7125 - acc: 0.6701\n","Epoch 19/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.7312 - acc: 0.6684\n","Epoch 20/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.7442 - acc: 0.6354\n","Epoch 21/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.7282 - acc: 0.6545\n","Epoch 22/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.6540 - acc: 0.6736\n","Epoch 23/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6407 - acc: 0.6667\n","Epoch 24/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6555 - acc: 0.6788\n","Epoch 25/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.6275 - acc: 0.6875\n","Epoch 26/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.6484 - acc: 0.6823\n","Epoch 27/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.6128 - acc: 0.6771\n","Epoch 28/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.6182 - acc: 0.6875\n","Epoch 29/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6079 - acc: 0.6684\n","Epoch 30/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.6011 - acc: 0.6875\n","Epoch 31/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.6018 - acc: 0.6806\n","Epoch 32/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5961 - acc: 0.6875\n","Epoch 33/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6183 - acc: 0.6823\n","Epoch 34/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.6134 - acc: 0.7014\n","Epoch 35/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5996 - acc: 0.6771\n","Epoch 36/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.6064 - acc: 0.7014\n","Epoch 37/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.6406 - acc: 0.6719\n","Epoch 38/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5965 - acc: 0.7118\n","Epoch 39/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5935 - acc: 0.7101\n","Epoch 40/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5764 - acc: 0.6875\n","Epoch 41/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.6143 - acc: 0.6892\n","Epoch 42/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.6113 - acc: 0.6962\n","Epoch 43/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5940 - acc: 0.6944\n","Epoch 44/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5862 - acc: 0.7101\n","Epoch 45/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5808 - acc: 0.7014\n","Epoch 46/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5881 - acc: 0.6944\n","Epoch 47/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5676 - acc: 0.7031\n","Epoch 48/100\n","576/576 [==============================] - 0s 41us/step - loss: 0.6119 - acc: 0.6806\n","Epoch 49/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5786 - acc: 0.7066\n","Epoch 50/100\n","576/576 [==============================] - 0s 58us/step - loss: 0.5719 - acc: 0.7118\n","Epoch 51/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5901 - acc: 0.7049\n","Epoch 52/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5546 - acc: 0.7205\n","Epoch 53/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5887 - acc: 0.6927\n","Epoch 54/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.6073 - acc: 0.6927\n","Epoch 55/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5768 - acc: 0.7101\n","Epoch 56/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5734 - acc: 0.7031\n","Epoch 57/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5691 - acc: 0.7049\n","Epoch 58/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.6043 - acc: 0.7118\n","Epoch 59/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5695 - acc: 0.6997\n","Epoch 60/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5535 - acc: 0.7118\n","Epoch 61/100\n","576/576 [==============================] - 0s 50us/step - loss: 0.5832 - acc: 0.6997\n","Epoch 62/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5798 - acc: 0.6979\n","Epoch 63/100\n","576/576 [==============================] - 0s 46us/step - loss: 0.5611 - acc: 0.7292\n","Epoch 64/100\n","576/576 [==============================] - 0s 61us/step - loss: 0.5558 - acc: 0.7396\n","Epoch 65/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5621 - acc: 0.7205\n","Epoch 66/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5447 - acc: 0.7205\n","Epoch 67/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5707 - acc: 0.7014\n","Epoch 68/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5516 - acc: 0.7344\n","Epoch 69/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5407 - acc: 0.7344\n","Epoch 70/100\n","576/576 [==============================] - 0s 59us/step - loss: 0.5583 - acc: 0.7031\n","Epoch 71/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5513 - acc: 0.7326\n","Epoch 72/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5469 - acc: 0.7309\n","Epoch 73/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5466 - acc: 0.7222\n","Epoch 74/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5439 - acc: 0.7361\n","Epoch 75/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5704 - acc: 0.7118\n","Epoch 76/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5914 - acc: 0.7118\n","Epoch 77/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5386 - acc: 0.7274\n","Epoch 78/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5780 - acc: 0.7292\n","Epoch 79/100\n","576/576 [==============================] - 0s 52us/step - loss: 0.5521 - acc: 0.7309\n","Epoch 80/100\n","576/576 [==============================] - 0s 54us/step - loss: 0.5378 - acc: 0.7448\n","Epoch 81/100\n","576/576 [==============================] - 0s 48us/step - loss: 0.5646 - acc: 0.7257\n","Epoch 82/100\n","576/576 [==============================] - 0s 51us/step - loss: 0.5449 - acc: 0.7309\n","Epoch 83/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5226 - acc: 0.7465\n","Epoch 84/100\n","576/576 [==============================] - 0s 49us/step - loss: 0.5402 - acc: 0.7240\n","Epoch 85/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5743 - acc: 0.6997\n","Epoch 86/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5729 - acc: 0.7274\n","Epoch 87/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5270 - acc: 0.7396\n","Epoch 88/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5616 - acc: 0.7188\n","Epoch 89/100\n","576/576 [==============================] - 0s 42us/step - loss: 0.5451 - acc: 0.7274\n","Epoch 90/100\n","576/576 [==============================] - 0s 45us/step - loss: 0.5488 - acc: 0.7326\n","Epoch 91/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5702 - acc: 0.7101\n","Epoch 92/100\n","576/576 [==============================] - 0s 40us/step - loss: 0.5233 - acc: 0.7483\n","Epoch 93/100\n","576/576 [==============================] - 0s 43us/step - loss: 0.5199 - acc: 0.7465\n","Epoch 94/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5562 - acc: 0.7153\n","Epoch 95/100\n","576/576 [==============================] - 0s 39us/step - loss: 0.5784 - acc: 0.7014\n","Epoch 96/100\n","576/576 [==============================] - 0s 38us/step - loss: 0.5542 - acc: 0.7361\n","Epoch 97/100\n","576/576 [==============================] - 0s 66us/step - loss: 0.5546 - acc: 0.7292\n","Epoch 98/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5280 - acc: 0.7413\n","Epoch 99/100\n","576/576 [==============================] - 0s 47us/step - loss: 0.5241 - acc: 0.7465\n","Epoch 100/100\n","576/576 [==============================] - 0s 44us/step - loss: 0.5177 - acc: 0.7361\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19SYVY4DH7OW","colab_type":"code","outputId":"e6279e29-ab85-46eb-ca0e-14fbcf37038e","executionInfo":{"status":"ok","timestamp":1584729299263,"user_tz":300,"elapsed":272,"user":{"displayName":"Dileep Reddy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUeOYhgkcy7IK_3VWG8xk-C8gxZpv-FF_AuC_N4w=s64","userId":"05071958161747460000"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"source":["print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_1 (Dense)              (None, 21)                189       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 22        \n","=================================================================\n","Total params: 211\n","Trainable params: 211\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","192/192 [==============================] - 0s 169us/step\n","[0.636214425166448, 0.6875]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EBYPua9zH-E6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}